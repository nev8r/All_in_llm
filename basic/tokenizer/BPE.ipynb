{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92721b66",
   "metadata": {},
   "source": [
    "1. 准备语料,初始化vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c794501",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"Transformers: the model-definition framework for state-of-the-art machine learning models in text, vision, audio, and multimodal models, for both inference and training.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24c9f1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|endoftext|>',\n",
       " ' ',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " ':',\n",
       " 'T',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "for ch in corpus:\n",
    "    if ch not in vocab:\n",
    "        vocab.append(ch)\n",
    "vocab = [\"<|endoftext|>\"] + sorted(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f32b0",
   "metadata": {},
   "source": [
    "2. 计算词频（便于后面计算），这里我们先pre_tokenizer（gpt2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fbe5cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Transformers', ':', ' the', ' model', '-', 'definition', ' framework', ' for', ' state', '-', 'of', '-', 'the', '-', 'art', ' machine', ' learning', ' models', ' in', ' text', ',', ' vision', ',', ' audio', ',', ' and', ' multimodal', ' models', ',', ' for', ' both', ' inference', ' and', ' training', '.']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "# GPT-2 原始 pre-tokenizer 正则\n",
    "gpt2_regex = re.compile(\n",
    "    r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    ")\n",
    "def pre_tokenize_str(text: str) -> list[str]:\n",
    "    tokens = gpt2_regex.findall(text)\n",
    "    return tokens\n",
    "print(pre_tokenize_str(corpus))\n",
    "# ['Transformers', ':', ' the', ' model', '-', 'definition', ' framework', ' for', ' state', '-', 'of', '-', 'the', '-', 'art', ' machine', ' learning', ' models', ' in', ' text', ',', ' vision', ',', ' audio', ',', ' and', ' multimodal', ' models', ',', ' for', ' both', ' inference', ' and', ' training', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbfc9ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {('T', 'r', 'a', 'n', 's', 'f', 'o', 'r', 'm', 'e', 'r', 's'): 1, (':',): 1, (' ', 't', 'h', 'e'): 1, (' ', 'm', 'o', 'd', 'e', 'l'): 1, ('-',): 4, ('d', 'e', 'f', 'i', 'n', 'i', 't', 'i', 'o', 'n'): 1, (' ', 'f', 'r', 'a', 'm', 'e', 'w', 'o', 'r', 'k'): 1, (' ', 'f', 'o', 'r'): 2, (' ', 's', 't', 'a', 't', 'e'): 1, ('o', 'f'): 1, ('t', 'h', 'e'): 1, ('a', 'r', 't'): 1, (' ', 'm', 'a', 'c', 'h', 'i', 'n', 'e'): 1, (' ', 'l', 'e', 'a', 'r', 'n', 'i', 'n', 'g'): 1, (' ', 'm', 'o', 'd', 'e', 'l', 's'): 2, (' ', 'i', 'n'): 1, (' ', 't', 'e', 'x', 't'): 1, (',',): 4, (' ', 'v', 'i', 's', 'i', 'o', 'n'): 1, (' ', 'a', 'u', 'd', 'i', 'o'): 1, (' ', 'a', 'n', 'd'): 2, (' ', 'm', 'u', 'l', 't', 'i', 'm', 'o', 'd', 'a', 'l'): 1, (' ', 'b', 'o', 't', 'h'): 1, (' ', 'i', 'n', 'f', 'e', 'r', 'e', 'n', 'c', 'e'): 1, (' ', 't', 'r', 'a', 'i', 'n', 'i', 'n', 'g'): 1, ('.',): 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_word_freqs(text:str):\n",
    "    words = pre_tokenize_str(text)\n",
    "    word_freqs = defaultdict(int)\n",
    "    \n",
    "    for word in words:\n",
    "        word_freqs[tuple(word)] += 1\n",
    "    \n",
    "    return word_freqs\n",
    "\n",
    "print(get_word_freqs(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9151c0",
   "metadata": {},
   "source": [
    "3. 计算相邻pairs频率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aa20696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('T', 'r'): 1,\n",
       "             ('r', 'a'): 3,\n",
       "             ('a', 'n'): 3,\n",
       "             ('n', 's'): 1,\n",
       "             ('s', 'f'): 1,\n",
       "             ('f', 'o'): 3,\n",
       "             ('o', 'r'): 4,\n",
       "             ('r', 'm'): 1,\n",
       "             ('m', 'e'): 2,\n",
       "             ('e', 'r'): 2,\n",
       "             ('r', 's'): 1,\n",
       "             (' ', 't'): 3,\n",
       "             ('t', 'h'): 3,\n",
       "             ('h', 'e'): 2,\n",
       "             (' ', 'm'): 5,\n",
       "             ('m', 'o'): 4,\n",
       "             ('o', 'd'): 4,\n",
       "             ('d', 'e'): 4,\n",
       "             ('e', 'l'): 3,\n",
       "             ('e', 'f'): 1,\n",
       "             ('f', 'i'): 1,\n",
       "             ('i', 'n'): 7,\n",
       "             ('n', 'i'): 3,\n",
       "             ('i', 't'): 1,\n",
       "             ('t', 'i'): 2,\n",
       "             ('i', 'o'): 3,\n",
       "             ('o', 'n'): 2,\n",
       "             (' ', 'f'): 3,\n",
       "             ('f', 'r'): 1,\n",
       "             ('a', 'm'): 1,\n",
       "             ('e', 'w'): 1,\n",
       "             ('w', 'o'): 1,\n",
       "             ('r', 'k'): 1,\n",
       "             (' ', 's'): 1,\n",
       "             ('s', 't'): 1,\n",
       "             ('t', 'a'): 1,\n",
       "             ('a', 't'): 1,\n",
       "             ('t', 'e'): 2,\n",
       "             ('o', 'f'): 1,\n",
       "             ('a', 'r'): 2,\n",
       "             ('r', 't'): 1,\n",
       "             ('m', 'a'): 1,\n",
       "             ('a', 'c'): 1,\n",
       "             ('c', 'h'): 1,\n",
       "             ('h', 'i'): 1,\n",
       "             ('n', 'e'): 1,\n",
       "             (' ', 'l'): 1,\n",
       "             ('l', 'e'): 1,\n",
       "             ('e', 'a'): 1,\n",
       "             ('r', 'n'): 1,\n",
       "             ('n', 'g'): 2,\n",
       "             ('l', 's'): 2,\n",
       "             (' ', 'i'): 2,\n",
       "             ('e', 'x'): 1,\n",
       "             ('x', 't'): 1,\n",
       "             (' ', 'v'): 1,\n",
       "             ('v', 'i'): 1,\n",
       "             ('i', 's'): 1,\n",
       "             ('s', 'i'): 1,\n",
       "             (' ', 'a'): 3,\n",
       "             ('a', 'u'): 1,\n",
       "             ('u', 'd'): 1,\n",
       "             ('d', 'i'): 1,\n",
       "             ('n', 'd'): 2,\n",
       "             ('m', 'u'): 1,\n",
       "             ('u', 'l'): 1,\n",
       "             ('l', 't'): 1,\n",
       "             ('i', 'm'): 1,\n",
       "             ('d', 'a'): 1,\n",
       "             ('a', 'l'): 1,\n",
       "             (' ', 'b'): 1,\n",
       "             ('b', 'o'): 1,\n",
       "             ('o', 't'): 1,\n",
       "             ('n', 'f'): 1,\n",
       "             ('f', 'e'): 1,\n",
       "             ('r', 'e'): 1,\n",
       "             ('e', 'n'): 1,\n",
       "             ('n', 'c'): 1,\n",
       "             ('c', 'e'): 1,\n",
       "             ('t', 'r'): 1,\n",
       "             ('a', 'i'): 1})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_pair_freqs(word_freqs):\n",
    "    pair_freqs = defaultdict(int)\n",
    "    for word, freq in word_freqs.items():\n",
    "        if len(word) == 1:\n",
    "            continue\n",
    "        for i in range(len(word) - 1):\n",
    "            pair = (word[i], word[i + 1])\n",
    "            pair_freqs[pair] += freq\n",
    "    return pair_freqs\n",
    "compute_pair_freqs(get_word_freqs(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a731001",
   "metadata": {},
   "source": [
    "4. 找到频率最大的pair 并合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7be3e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2346973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair(a, b, word_freqs):\n",
    "    new_word_freqs = {}\n",
    "    for word, freq in word_freqs.items():  \n",
    "        if len(word) == 1:\n",
    "            new_word_freqs[word] = freq\n",
    "            continue\n",
    "        word_list = list(word)  \n",
    "        i = 0\n",
    "        while i < len(word_list) - 1:\n",
    "            if word_list[i] == a and word_list[i + 1] == b:\n",
    "                word_list[i:i+2] = [a + b]  \n",
    "                i += 1  \n",
    "            else:\n",
    "                i += 1\n",
    "        new_word_freqs[tuple(word_list)] = freq  \n",
    "    return new_word_freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94aa545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(word_freqs,pair_freqs):\n",
    "    best_pair = \"\"\n",
    "    max_freq = None\n",
    "    for pair, freq in pair_freqs.items():\n",
    "        if max_freq is None or max_freq < freq:\n",
    "            best_pair = pair\n",
    "            max_freq = freq\n",
    "    merges.append(best_pair)\n",
    "    vocab.append(best_pair[0] + best_pair[1])\n",
    "    return merge_pair(best_pair[0],best_pair[1],word_freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe21698",
   "metadata": {},
   "source": [
    "5. 设定vocab_size,重复3、4训练最后vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51439d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(vocab_size,word_freqs):\n",
    "    while len(vocab) < vocab_size:\n",
    "        pair_freqs = compute_pair_freqs(word_freqs)\n",
    "        word_freqs = train_step(word_freqs,pair_freqs)\n",
    "        \n",
    "train(80,get_word_freqs(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902596fe",
   "metadata": {},
   "source": [
    "6. 训练好的merges和vocab继续tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a370945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpe_encode_word(word, merges):\n",
    "    \"\"\"对单个word执行BPE编码\"\"\"\n",
    "    word = list(word)\n",
    "    for merge in merges:  \n",
    "        a, b = merge\n",
    "        i = 0\n",
    "        new_word = []\n",
    "        while i < len(word):\n",
    "            if i < len(word) - 1 and word[i] == a and word[i + 1] == b:\n",
    "                new_word.append(a + b)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        word = new_word  \n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e7632b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transformers',\n",
       " ':',\n",
       " ' the',\n",
       " ' model',\n",
       " '-',\n",
       " 'definition',\n",
       " ' framework',\n",
       " ' for',\n",
       " ' state',\n",
       " '-',\n",
       " 'of',\n",
       " '-',\n",
       " 'the',\n",
       " '-',\n",
       " 'art',\n",
       " ' mac',\n",
       " 'h',\n",
       " 'in',\n",
       " 'e',\n",
       " ' ',\n",
       " 'l',\n",
       " 'e',\n",
       " 'ar',\n",
       " 'n',\n",
       " 'ing',\n",
       " ' models',\n",
       " ' in',\n",
       " ' t',\n",
       " 'e',\n",
       " 'x',\n",
       " 't',\n",
       " ',',\n",
       " ' ',\n",
       " 'v',\n",
       " 'i',\n",
       " 's',\n",
       " 'ion',\n",
       " ',',\n",
       " ' a',\n",
       " 'u',\n",
       " 'd',\n",
       " 'io',\n",
       " ',',\n",
       " ' and',\n",
       " ' m',\n",
       " 'u',\n",
       " 'l',\n",
       " 't',\n",
       " 'i',\n",
       " 'm',\n",
       " 'od',\n",
       " 'a',\n",
       " 'l',\n",
       " ' models',\n",
       " ',',\n",
       " ' for',\n",
       " ' ',\n",
       " 'b',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " ' in',\n",
       " 'f',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " ' and',\n",
       " ' t',\n",
       " 'ra',\n",
       " 'in',\n",
       " 'ing',\n",
       " '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text:str):\n",
    "    tokens = pre_tokenize_str(text)\n",
    "    output_tokens = []\n",
    "    for token in tokens:\n",
    "        encoded = bpe_encode_word(token, merges)\n",
    "        output_tokens.extend(encoded)\n",
    "    return output_tokens\n",
    "tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bb91bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 5, 57, 37, 3, 63, 69, 43, 74, 3, 75, 3, 76, 3, 77, 79, 14, 28, 11, 1, 17, 11, 44, 19, 45, 46, 47, 34, 11, 27, 23, 2, 1, 25, 15, 22, 42, 2, 39, 24, 10, 38, 2, 49, 29, 24, 17, 23, 15, 18, 31, 7, 17, 46, 2, 43, 1, 8, 20, 23, 14, 47, 12, 11, 21, 11, 19, 9, 11, 49, 34, 32, 28, 45, 4]\n"
     ]
    }
   ],
   "source": [
    "def encode(text: str):\n",
    "    \"\"\"完整编码流程：文本 -> tokens -> token_ids\"\"\"\n",
    "    tokens = tokenize(text)\n",
    "    token_ids = [vocab.index(token) for token in tokens]\n",
    "    return token_ids\n",
    "\n",
    "print(encode(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7817fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def decode(token_ids: list[int]):\n",
    "    \"\"\"将 token_ids 转回原始文本\"\"\"\n",
    "    tokens = [vocab[i] for i in token_ids]\n",
    "    text = \"\".join(tokens)\n",
    "    return text\n",
    "print(decode(encode(corpus)) == corpus) # True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "All_in_llm (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
