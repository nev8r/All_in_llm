from datasets import load_dataset
from transformers import AutoTokenizer
import numpy as np
from tqdm import tqdm
import warnings

# -------------------
# é…ç½®åŒº
# -------------------
model_name = "/root/All_in_llm/models/Qwen2.5-Math-7B"  # æœ¬åœ°æˆ–HFè·¯å¾„
dataset_path = "/root/All_in_llm/post_training/sft/data/gsm8k"
subset = "main"           # Hugging Face åŠ è½½å­é›†åç§°
split = "train"           # "train" æˆ– "test"
sample_limit = None       # None è¡¨ç¤ºå…¨é‡
# -------------------

warnings.filterwarnings("ignore")

print(f"ğŸ”¹ Loading dataset: {dataset_path}/{subset} ({split}) ...")
dataset = load_dataset(dataset_path, subset, split=split)

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# -------- ç»Ÿè®¡å‡½æ•° --------
def analyze_lengths(lengths, title):
    lengths = np.array(lengths)
    print(f"\n===== {title} =====")
    print(f"Samples analyzed: {len(lengths)}")
    print(f"Mean length: {np.mean(lengths):.1f}")
    print(f"Median length: {np.median(lengths):.1f}")
    print(f"Max length: {np.max(lengths)}")
    print(f"95th percentile: {np.percentile(lengths, 95):.1f}")
    print(f"99th percentile: {np.percentile(lengths, 99):.1f}")
    recommended = int(np.percentile(lengths, 99)) + 128
    print(f"âœ… Recommended max_length: {recommended}")
    return recommended

# -------- æ— æ¨¡æ¿ç»Ÿè®¡ --------
plain_lengths = []
for i, item in enumerate(tqdm(dataset, desc="Tokenizing (plain Q/A)")):
    if sample_limit and i >= sample_limit:
        break
    text = f"Question: {item['question']}\nAnswer: {item['answer']}"
    tokens = tokenizer(text, truncation=False, add_special_tokens=True)["input_ids"]
    plain_lengths.append(len(tokens))

plain_maxlen = analyze_lengths(plain_lengths, "No Template (plain Q/A)")

# -------- å¸¦ Qwen Chat æ¨¡æ¿ç»Ÿè®¡ --------
chat_lengths = []
for i, item in enumerate(tqdm(dataset, desc="Tokenizing (Qwen chat template)")):
    if sample_limit and i >= sample_limit:
        break

    # æ„é€ ç¬¦åˆ Qwen2.5 çš„ ChatML è¾“å…¥
    messages = [
        {"role": "system", "content": "You are a helpful math assistant."},
        {"role": "user", "content": item["question"]},
        {"role": "assistant", "content": f"<think>{item['answer']}</think>"}
    ]

    tokens = tokenizer.apply_chat_template(
        messages, tokenize=True, add_generation_prompt=False
    )
    chat_lengths.append(len(tokens))

chat_maxlen = analyze_lengths(chat_lengths, "With Qwen2.5 Chat Template")

print("\nğŸ“Š Summary:")
print(f"  â†’ Plain Q/A 99% length + buffer: {plain_maxlen}")
print(f"  â†’ Chat template 99% length + buffer: {chat_maxlen}")
